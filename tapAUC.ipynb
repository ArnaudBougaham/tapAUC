{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf759b-0118-4f11-b83e-8437f2bdc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import datetime\n",
    "from time import time\n",
    "\n",
    "start_time=datetime.datetime.now()\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.set_printoptions(precision=6)\n",
    "np.set_printoptions(precision=6)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = 'PCBA_Metrics.txt'\n",
    "\n",
    "# Load and preprocess the data\n",
    "dirname = os.path.abspath('')\n",
    "path = os.path.join(dirname, 'tapAUC')\n",
    "metric_df_include = pd.read_csv(os.path.join(path, dataset), index_col=False)\n",
    "# Impute NaN values with the average column\n",
    "metric_df_include.fillna(metric_df_include.mean(), inplace=True)\n",
    "# Drop all constant columns\n",
    "metric_df_include = metric_df_include.drop(metric_df_include.iloc[:, 8:].columns[metric_df_include.iloc[:, 8:].nunique() <= 1], axis=1)\n",
    "# Replace +/-inf values with np.finfo(np.float32).max/min\n",
    "metric_df_include = metric_df_include.replace(' inf', np.finfo(np.float32).max)\n",
    "metric_df_include = metric_df_include.replace(' -inf', np.finfo(np.float32).min)\n",
    "# Drop highly correlated features\n",
    "corr_matrix = metric_df_include.iloc[:, 8:].corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "metric_df_include.drop(to_drop, axis=1, inplace=True)\n",
    "col_names = metric_df_include.columns.values\n",
    "metric_df_include = metric_df_include.set_axis(col_names, axis=1, inplace=False)\n",
    "data_full = metric_df_include.reset_index(drop=True)\n",
    "\n",
    "data_full.loc[data_full[\"status\"] == \"NG\", \"status\"] = 1\n",
    "data_full.loc[data_full[\"status\"] == \"OK\", \"status\"] = 0\n",
    "X = data_full.iloc[:, 8:].to_numpy()\n",
    "y = data_full.iloc[:, 2].to_numpy().astype(np.float32)\n",
    "test_files = data_full['test_file'].to_numpy()  # Extract test_file column\n",
    "statuses = data_full['status'].astype(str).to_numpy()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, test_files=None, statuses=None):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "        self.test_files = test_files\n",
    "        self.statuses = statuses\n",
    "    def __getitem__(self, index):\n",
    "        item = (self.X[index], self.y[index])\n",
    "        if self.test_files is not None and self.statuses is not None:\n",
    "            item += (self.test_files[index], self.statuses[index])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(feat_count, int(feat_count/2))\n",
    "        self.layer_2 = nn.Linear(int(feat_count/2), int(feat_count/2))\n",
    "        self.layer_out = nn.Linear(int(feat_count/2), 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(int(feat_count/2))\n",
    "        self.batchnorm2 = nn.BatchNorm1d(int(feat_count/2))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class tapAUCLoss(nn.modules.loss._Loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        if not isinstance(y_true, torch.Tensor):\n",
    "            y_true = torch.tensor(y_true)\n",
    "        if isinstance(y_pred, tuple):\n",
    "            y_pred = y_pred.values\n",
    "        y_true = y_true.to(y_pred.device)\n",
    "        positive = y_pred[y_true == 1]\n",
    "        negative = y_pred[y_true == 0]\n",
    "        loss = torch.nn.functional.relu((negative.view(1, -1) + gamma - positive.view(-1, 1)) ** 2).mean()\n",
    "        return loss\n",
    "\n",
    "def get_metric(mode,y_pred, y_true, th=None):\n",
    "    y_pred = y_pred.cpu().detach().numpy()\n",
    "    y_true = y_true.cpu().detach().numpy()\n",
    "    positive = y_pred[y_true == 1]\n",
    "    negative = y_pred[y_true == 0]\n",
    "    if th == None:\n",
    "        if mode == 'std':\n",
    "            allfpr, alltpr, thresholds = roc_curve(y_true, y_pred)\n",
    "            accuracy_scores = [accuracy_score(y_true, [m >= thresh for m in y_pred]) for thresh in thresholds]\n",
    "            accuracies = np.array(accuracy_scores)\n",
    "            acc = accuracies.max()*100\n",
    "            th = thresholds[accuracies.argmax()]\n",
    "        else:\n",
    "             th = min(positive)\n",
    "    FP = len(negative[negative >= th])\n",
    "    TP = len(positive[positive >= th])\n",
    "    TN = len(negative[negative < th])\n",
    "    FN = len(positive[positive < th])\n",
    "    if ((th != None and mode == 'std') or (mode == 'zfn')):\n",
    "        acc = [(TP+TN)/(TP+FN+FP+TN) if (TP+FN+FP+TN)!=0 else 0][0]\n",
    "    specificity= [1-(FP/(FP+TN)) if (FP+TN)!=0 else 1][0]\n",
    "    sensitivity= [TP/(FN+TP) if (FN+TP)!=0 else 0][0]\n",
    "    gmean=np.sqrt(sensitivity*specificity)\n",
    "    precision= [TP/(TP+FP) if (TP+FP)!=0 else 0][0]\n",
    "    f1score=[(((1**2)+1)*precision*sensitivity)/(((1**2)*precision)+sensitivity) if (((1**2)*precision)+sensitivity)!=0 else 0][0]\n",
    "    f2score=[(((2**2)+1)*precision*sensitivity)/(((2**2)*precision)+sensitivity) if (((2**2)*precision)+sensitivity)!=0 else 0][0]\n",
    "    return th,TP,FP,TN,FN,acc,sensitivity,specificity,gmean,precision,f1score,f2score \n",
    "\n",
    "def cv(X, y, test_files, statuses, repeat, n_splits=5):\n",
    "    train_metrics=[[] for _ in range(n_splits)]\n",
    "    test_metrics=[[] for _ in range(n_splits)]\n",
    "    \n",
    "     # Perform k-fold cross-validation on the train+val set\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=repeat)   \n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "        # Split data into train and validation sets\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        test_files_train, test_files_test = test_files[train_index], test_files[test_index]\n",
    "        statuses_train, statuses_test = statuses[train_index], statuses[test_index]\n",
    "\n",
    "        # Create datasets and loaders\n",
    "        train_dataset = CustomDataset(X_train, y_train, test_files=test_files_train, statuses=statuses_train)\n",
    "        test_dataset = CustomDataset(X_test, y_test, test_files=test_files_test, statuses=statuses_test)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "        \n",
    "        # Initialize model and optimizer\n",
    "        model = binaryClassification()\n",
    "        model.to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(1, total_epochs + 1):\n",
    "            model.train()\n",
    "            for X_batch_train, y_batch_train, _, _ in train_loader:\n",
    "                X_batch_train, y_batch_train = X_batch_train.to(device), y_batch_train.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_pred_train = model(X_batch_train)\n",
    "                if epoch >= int(total_epochs * e_warmup):\n",
    "                    y_ = y_batch_train.clone()\n",
    "                    y_score_train = y_pred_train.clone().flatten()\n",
    "                    y_score_train_idx = (-y_score_train).argsort()\n",
    "                    y_score_sorted_train = y_score_train[y_score_train_idx]\n",
    "                    y_sorted_train = y_[y_score_train_idx]\n",
    "                    S_minus = y_score_sorted_train[torch.where(y_sorted_train == 0)]\n",
    "                    S_minus_idx = torch.where(y_sorted_train == 0)[0]\n",
    "                    S_plus = y_score_sorted_train[torch.where(y_sorted_train == 1)]\n",
    "                    S_plus_idx = torch.where(y_sorted_train == 1)[0]\n",
    "                    if neg_count != 1:\n",
    "                        S_minus_alpha_idx = S_minus_idx[-int(len(S_minus_idx) * neg_count):]\n",
    "                    else:\n",
    "                        S_minus_alpha_idx = S_minus_idx[-1:]\n",
    "                    S_minus_alpha = y_score_sorted_train[S_minus_alpha_idx]\n",
    "                    S_alpha, _ = torch.sort(torch.cat((S_minus_alpha, S_plus), axis=0), descending=True)\n",
    "                    S_alpha_idx, _ = torch.sort(torch.cat((S_minus_alpha_idx, S_plus_idx), axis=0), descending=False)\n",
    "                    y_train_alpha = y_sorted_train[S_alpha_idx]\n",
    "                    loss = tapAUCLoss()(S_alpha, y_train_alpha)\n",
    "                    pred_train_lst[repeat-1][fold-1][epoch-1].append(S_alpha)\n",
    "                    label_train_lst[repeat-1][fold-1][epoch-1].append(y_train_alpha)\n",
    "                else:\n",
    "                    loss = tapAUCLoss()(y_pred_train, y_batch_train.unsqueeze(1))\n",
    "                    pred_train_lst[repeat-1][fold-1][epoch-1].append(y_pred_train)\n",
    "                    label_train_lst[repeat-1][fold-1][epoch-1].append(y_batch_train.unsqueeze(1))\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "            train_std_th,train_std_TP,train_std_FP,train_std_TN,train_std_FN,train_std_acc,train_std_sensitivity,train_std_specificity,train_std_gmean,train_std_precision,train_std_f1score,train_std_f2score=get_metric('std',y_pred_train, y_batch_train.unsqueeze(1))\n",
    "            train_zfn_th,train_zfn_TP,train_zfn_FP,train_zfn_TN,train_zfn_FN,train_zfn_acc,train_zfn_sensitivity,train_zfn_specificity,train_zfn_gmean,train_zfn_precision,train_zfn_f1score,train_zfn_f2score=get_metric('zfn',y_pred_train, y_batch_train.unsqueeze(1))\n",
    "            train_zfn_th_lst[repeat-1][fold-1][epoch-1].append(train_zfn_th)\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            test_std_acc, test_std_th = 0, 0\n",
    "            test_zfn_acc, test_zfn_th = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for X_batch_test, y_batch_test, _, _ in test_loader:\n",
    "                    X_batch_test = X_batch_test.to(device)\n",
    "                    y_pred_test = model(X_batch_test)\n",
    "                    pred_test_lst[repeat-1][fold-1][epoch-1].append(y_pred_test)\n",
    "                    label_test_lst[repeat-1][fold-1][epoch-1].append(y_batch_test)\n",
    "                    test_std_th,test_std_TP,test_std_FP,test_std_TN,test_std_FN,test_std_acc,test_std_sensitivity,test_std_specificity,test_std_gmean,test_std_precision,test_std_f1score,test_std_f2score=get_metric('std',y_pred_test, y_batch_test.unsqueeze(1),train_std_th)\n",
    "                    test_zfn_th,test_zfn_TP,test_zfn_FP,test_zfn_TN,test_zfn_FN,test_zfn_acc,test_zfn_sensitivity,test_zfn_specificity,test_zfn_gmean,test_zfn_precision,test_zfn_f1score,test_zfn_f2score=get_metric('zfn',y_pred_test, y_batch_test.unsqueeze(1),train_zfn_th)\n",
    "                    test_zfn_th_lst[repeat-1][fold-1][epoch-1].append(test_zfn_th)\n",
    "            \n",
    "            if epoch == total_epochs:\n",
    "                train_metrics[fold-1]=[fold,repeat,loss.item(),train_std_th,train_std_TP,train_std_FP,train_std_TN,train_std_FN,train_std_acc,train_std_sensitivity,train_std_specificity,train_std_gmean,train_std_precision,train_std_f1score,train_std_f2score,train_zfn_th,train_zfn_TP,train_zfn_FP,train_zfn_TN,train_zfn_FN,train_zfn_acc,train_zfn_sensitivity,train_zfn_specificity,train_zfn_gmean,train_zfn_precision,train_zfn_f1score,train_zfn_f2score]\n",
    "                test_metrics[fold-1]=[fold,repeat,'-',test_std_th,test_std_TP,test_std_FP,test_std_TN,test_std_FN,test_std_acc,test_std_sensitivity,test_std_specificity,test_std_gmean,test_std_precision,test_std_f1score,test_std_f2score,test_zfn_th,test_zfn_TP,test_zfn_FP,test_zfn_TN,test_zfn_FN,test_zfn_acc,test_zfn_sensitivity,test_zfn_specificity,test_zfn_gmean,test_zfn_precision,test_zfn_f1score,test_zfn_f2score]\n",
    "\n",
    "    return train_metrics, test_metrics, pred_train_lst, pred_test_lst, label_train_lst, label_test_lst, train_zfn_th_lst, test_zfn_th_lst\n",
    "        \n",
    "def run_code(i_loop, current_file, total_epochs, neg_count, gamma, e_warmup, n_repeats=5):\n",
    "    \n",
    "    n_splits = 5\n",
    "    pos_gt = np.sum(y == 1)\n",
    "    neg_gt = np.sum(y == 0)\n",
    "    repeat=0\n",
    "    train_metrics_repeat=[]\n",
    "    test_metrics_repeat=[]\n",
    "        \n",
    "    for _ in range(n_repeats):\n",
    "        repeat+=1\n",
    "        train_metrics, test_metrics, pred_train_lst, pred_test_lst, label_train_lst, label_test_lst, train_zfn_th_lst, test_zfn_th_lst = cv(X,y, test_files, statuses, repeat, n_splits=n_splits)\n",
    "        train_metrics_repeat.append(train_metrics)\n",
    "        test_metrics_repeat.append(test_metrics)\n",
    "   \n",
    "    if neg_count != '-':\n",
    "        if neg_count==1:\n",
    "            neg_count=str(neg_count)\n",
    "        else:\n",
    "            neg_count=str(neg_count)+'%'\n",
    "            \n",
    "    def log_results(metric_list,split):\n",
    "        \n",
    "        losses=[]\n",
    "        std_ths,std_TPs,std_FPs,std_TNs,std_FNs,std_accs,std_sensitivitys,std_specificitys,std_gmeans,std_precisions,std_f1scores,std_f2scores=[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "        zfn_ths,zfn_TPs,zfn_FPs,zfn_TNs,zfn_FNs,zfn_accs,zfn_sensitivitys,zfn_specificitys,zfn_gmeans,zfn_precisions,zfn_f1scores,zfn_f2scores=[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "\n",
    "        # Extract metrics\n",
    "        for fold in metric_list:\n",
    "            for entry in fold:\n",
    "                losses.append(entry[2])\n",
    "                std_ths.append(entry[3])\n",
    "                std_TPs.append(entry[4])\n",
    "                std_FPs.append(entry[5])\n",
    "                std_TNs.append(entry[6])\n",
    "                std_FNs.append(entry[7])\n",
    "                std_accs.append(entry[8])\n",
    "                std_sensitivitys.append(entry[9])\n",
    "                std_specificitys.append(entry[10])\n",
    "                std_gmeans.append(entry[11])\n",
    "                std_precisions.append(entry[12])\n",
    "                std_f1scores.append(entry[13])\n",
    "                std_f2scores.append(entry[14])\n",
    "                zfn_ths.append(entry[15])\n",
    "                zfn_TPs.append(entry[16])\n",
    "                zfn_FPs.append(entry[17])\n",
    "                zfn_TNs.append(entry[18])\n",
    "                zfn_FNs.append(entry[19])\n",
    "                zfn_accs.append(entry[20])\n",
    "                zfn_sensitivitys.append(entry[21])\n",
    "                zfn_specificitys.append(entry[22])\n",
    "                zfn_gmeans.append(entry[23])\n",
    "                zfn_precisions.append(entry[24])\n",
    "                zfn_f1scores.append(entry[25])\n",
    "                zfn_f2scores.append(entry[26])\n",
    "                \n",
    "        if split == 'train':\n",
    "            mean_loss_line =  np.mean(losses)\n",
    "            std_loss_line =  np.std(losses)\n",
    "        else:\n",
    "            mean_loss_line =  '-'\n",
    "            std_loss_line =  '-'\n",
    "        averages = [\n",
    "            mean_loss_line,\n",
    "            np.mean(std_ths), np.mean(std_TPs), np.mean(std_FPs), np.mean(std_TNs),np.mean(std_FNs),\n",
    "            np.mean(std_accs), np.mean(std_sensitivitys), np.mean(std_specificitys), np.mean(std_gmeans),\n",
    "            np.mean(std_precisions),np.mean(std_f1scores), np.mean(std_f2scores),\n",
    "            np.mean(zfn_ths), np.mean(zfn_TPs), np.mean(zfn_FPs), np.mean(zfn_TNs),np.mean(zfn_FNs),\n",
    "            np.mean(zfn_accs), np.mean(zfn_sensitivitys), np.mean(zfn_specificitys), np.mean(zfn_gmeans),\n",
    "            np.mean(zfn_precisions),np.mean(zfn_f1scores), np.mean(zfn_f2scores)\n",
    "        ]\n",
    "        std_devs = [\n",
    "            std_loss_line,\n",
    "            np.std(std_ths), np.std(std_TPs), np.std(std_FPs), np.std(std_TNs),np.std(std_FNs),\n",
    "            np.std(std_accs), np.std(std_sensitivitys), np.std(std_specificitys), np.std(std_gmeans),\n",
    "            np.std(std_precisions),np.std(std_f1scores), np.std(std_f2scores),\n",
    "            np.std(zfn_ths), np.std(zfn_TPs), np.std(zfn_FPs), np.std(zfn_TNs),np.std(zfn_FNs),\n",
    "            np.std(zfn_accs), np.std(zfn_sensitivitys), np.std(zfn_specificitys), np.std(zfn_gmeans),\n",
    "            np.std(zfn_precisions),np.std(zfn_f1scores), np.std(zfn_f2scores)\n",
    "        ]\n",
    "        summary_entry = [averages] + [std_devs]\n",
    "        metric_list.insert(0, summary_entry)\n",
    "        with open(mean_file, \"a\") as m:\n",
    "            with open(stdev_file, \"a\") as s:\n",
    "                with open(detailed_file, \"a\") as d:\n",
    "                    for fold_index, fold in enumerate(metric_list):\n",
    "                        for entry_index, entry in enumerate(fold):\n",
    "                            if fold_index == 0:\n",
    "                                if entry_index == 0:\n",
    "                                    line_m = f\"{str(i_loop)},{dataset},{str(pos_gt)},{str(neg_gt)},{str(total_epochs)},{str(gamma)},{str(e_warmup)},{neg_count},{split},\" + \",\".join(map(str, entry[0:])) + \"\\n\"\n",
    "                                    m.write(line_m)\n",
    "                                else:\n",
    "                                    line_s = f\"{str(i_loop)},{dataset},{str(pos_gt)},{str(neg_gt)},{str(total_epochs)},{str(gamma)},{str(e_warmup)},{neg_count},{split},\" + \",\".join(map(str, entry[0:])) + \"\\n\"\n",
    "                                    s.write(line_s)\n",
    "                            else:\n",
    "                                line_d = f\"{str(i_loop)},{dataset},{str(pos_gt)},{str(neg_gt)},{str(total_epochs)},{str(gamma)},{str(e_warmup)},{neg_count},{split},\" + \",\".join(map(str, entry[0:])) + \"\\n\"\n",
    "                                d.write(line_d)\n",
    "        print(line_m)\n",
    "    log_results(train_metrics_repeat,'train')\n",
    "    log_results(test_metrics_repeat,'test')\n",
    "    return pred_train_lst, pred_test_lst, label_train_lst, label_test_lst, train_zfn_th_lst, test_zfn_th_lst\n",
    "\n",
    "i_loop=0\n",
    "feat_count = len(X[0])\n",
    "detailed_file='log_tapAUC_detail_'+str(round(time()))+'_'+dataset\n",
    "mean_file='log_tapAUC_mean_'+str(round(time()))+'_'+dataset\n",
    "stdev_file='log_tapAUC_stdev_'+str(round(time()))+'_'+dataset\n",
    "for current_file in [mean_file,stdev_file,detailed_file]:\n",
    "    if current_file == detailed_file:\n",
    "        with open(current_file, \"w\") as f:\n",
    "            f.write('idx, dataset,pos,neg,total_epochs,gamma,e_warmup,neg_count,split,fold,repeat,loss,std_ths,std_TPs,std_FPs,std_TNs,std_FNs,std_accs,std_sensitivitys,std_specificitys,std_gmeans,std_precisions,std_f1scores,std_f2scores,zfn_ths,zfn_TPs,zfn_FPs,zfn_TNs,zfn_FNs,zfn_accs,zfn_sensitivitys,zfn_specificitys,zfn_gmeans,zfn_precisions,zfn_f1scores,zfn_f2scores,'+'\\n')\n",
    "    else:\n",
    "        with open(current_file, \"w\") as f:\n",
    "            f.write('idx, dataset,pos,neg,total_epochs,gamma,e_warmup,neg_count,split,loss,std_ths,std_TPs,std_FPs,std_TNs,std_FNs,std_accs,std_sensitivitys,std_specificitys,std_gmeans,std_precisions,std_f1scores,std_f2scores,zfn_ths,zfn_TPs,zfn_FPs,zfn_TNs,zfn_FNs,zfn_accs,zfn_sensitivitys,zfn_specificitys,zfn_gmeans,zfn_precisions,zfn_f1scores,zfn_f2scores,'+'\\n')\n",
    "\n",
    "for total_epochs in [500]:\n",
    "    for gamma in [0.1]:\n",
    "        for e_warmup in [0.25]:\n",
    "            for neg_count in [0.05]:\n",
    "                i_loop+=1\n",
    "                start_hyper_time = datetime.datetime.now()\n",
    "                n_repeats=5\n",
    "                n_splits=5\n",
    "                pred_train_lst=[[[[] for _ in range(total_epochs)] for _ in range(n_splits)] for _ in range(n_repeats)]\n",
    "                label_train_lst=[[[[] for _ in range(total_epochs)] for _ in range(n_splits)] for _ in range(n_repeats)]\n",
    "                train_zfn_th_lst=[[[[] for _ in range(total_epochs)] for _ in range(n_splits)] for _ in range(n_repeats)]\n",
    "                pred_test_lst=[[[[] for _ in range(total_epochs)] for _ in range(n_splits)] for _ in range(n_repeats)]\n",
    "                label_test_lst=[[[[] for _ in range(total_epochs)] for _ in range(n_splits)] for _ in range(n_repeats)]\n",
    "                test_zfn_th_lst=[[[[] for _ in range(total_epochs)] for _ in range(n_splits)] for _ in range(n_repeats)]\n",
    "                pred_train_lst, pred_test_lst, label_train_lst, label_test_lst, train_zfn_th_lst, test_zfn_th_lst = run_code(i_loop,current_file,total_epochs,neg_count,gamma,e_warmup)\n",
    "                print('elapsed time :', datetime.datetime.now()-start_hyper_time)\n",
    "exec_time = datetime.datetime.now()-start_time\n",
    "print('exec time :', exec_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
